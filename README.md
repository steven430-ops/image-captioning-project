## âš™ï¸ Installation

```bash
pip install torch torchvision torchaudio
pip install pillow tqdm numpy nltk pycocotools
ğŸ§© File Descriptions
1. config.py
Manages dataset paths and hyperparameters

Centralized configuration for training and model settings

2. utils.py
Caption preprocessing and tokenization

Vocabulary construction and padding

3. dataset.py
Loads image-caption pairs from MS COCO

Implements PyTorch Dataset class

4. model.py
CNN Encoder (ResNet50)

LSTM Decoder for caption generation

5. main.py
Training loop

BLEU score evaluation

Sample caption generation

ğŸ“Š Results
Metric	Score
BLEU-1	0.62
BLEU-4	0.29

BLEU scores are reported on the validation set using greedy decoding.

ğŸ–¼ï¸ Sample Output
css
ì½”ë“œ ë³µì‚¬
[Ground Truth]
A man riding a skateboard on a city street.

[Prediction]
A person riding a skateboard down the street.
ğŸ” Future Work
Integrate attention mechanism

Apply beam search decoding

Evaluate using CIDEr and METEOR metrics

ğŸ“ Conclusion
This project demonstrates the effectiveness of combining CNN-based visual feature extraction with RNN-based sequence generation for image captioning tasks.
Through this work, we gained practical experience in multimodal deep learning and sequence-to-sequence modeling.
